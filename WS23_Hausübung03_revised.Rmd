---
title: "Hausübung 03 - Statistische Tests"
author: "Baier Sebastian, Magdalena Figlmüller, Alice Schwarzböck"
date: "2023-11-29"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Aufgabe 1

Ein Labor schickt seine Mitarbeiten zu einem Pipettiertraining und möchte
anschließend testen, ob sich dieses ausgezahlt hat, indem die mittleren
Zeiten zur Durchführen von 25 Pipettiervorgängen vor und nach dem
Training gemessen werden.

-) Hatte das Training irgendeinen Effekt?

-) Sollte die Firma, die das Labor betreibt,
die Mitarbeiter anderer Labors zu einem solchen Training schicken,
um ihre mittlere Arbeitszeit zu verringern?

-) Beantworten Sie diese Fragen auf dem 5% und 1% Niveau.


```{r Aufgabe1_Datenprüfung/-aufbereitung}
before <- c(1.36, 1.37, 1.29, 1.22, 1.38, 1.31, 1.40, 1.39, 1.30, 1.37)
after <- c(1.29, 1.25, 1.20, 1.26, 1.25, 1.23, 1.26, 1.31, 1.24, 1.31)

before_woOut <- c(1.36, 1.37, 1.29, 1.38, 1.31, 1.40, 1.39, 1.30, 1.37)
after_woOut <- c(1.29, 1.25, 1.20, 1.25, 1.23, 1.26, 1.31, 1.24, 1.31)

# Test auf Normalverteilung der Daten (Differenzen)
diff <- before - after
diff
shapiro.test(diff)

qqnorm(diff)
qqline(diff,col=2)

# ERWEITERUNG - Entfernen von Outlier -0.04
diff_woOut <- before_woOut - after_woOut
diff_woOut
shapiro.test(diff_woOut)

qqnorm(diff_woOut)
qqline(diff_woOut,col=2)

```

Da es sich in diesem Beispiel um die Untersuchung von zwei gepaarten Stichproben handelt, deren Differenz auf Signifikanz überprüft werden soll, sind die Differenzen auf Normalverteilung zu prüfen. Der Q-Q-Plot zeigt hier einen Ausreißer in der linken unteren Ecke, welcher in weiterer Folge entfernt wird. Für beide Datensätze, jenem mit und jenem ohne Auseißer, liefert der Shapiro-Wilk Test keine ausreichenden Hinweise, welche ein Verwerfen der Nullhypothese rechtfertigen würde, allerdings ist das Testergebnis des kleineren Datensatzes deutlich robuster.   
Die Daten sind somit annähernd normalverteilt und können mittels t-Test analysiert werden. Es soll im ersten Schritt überprüft werden, ob das Training einen Effekt hatte. Hier kann entweder der gepaarte T-test mit beiden Datensätzen oder der einfache T-Test mit den Differenzen durchgeführt werden. $\\$

Nullhypothese: Das Training hatte keinen Effekt.
$$H0: \mu_{before}=\mu_{after}$$  
Alternativhypothese: Das Training hatte einen Effekt.
$$HA: \mu_{before}\neq\mu_{after}$$  


```{r Aufgabe1_Test_different}

# T-test Variante1 (mit 2 gepaarten Stichproben)
t.test(before, after, paired = T, conf.level = 0.99)


# T-test Variante2 (mit Differenzen)
t.test(diff, conf.level = 0.99)
```

Die Teststatisik beträgt t = 4.9322. Der p-Wert liegt bei 0.0008109, somit kann die Nullhypothese sowohl auf dem 5% als auch auf dem 1% Niveau verworfen werden.

--> Das Training hatte einen Effekt!

Um zu überprüfen, ob das Training die mittlere Arbeitszeit verringert hat, wird die Nullhypothese um mu=0 (= tatsächliche Differenz zwischen den Datensätzen gleich 0) und die alternative = "greater" (--> 'before' hat einen höheren Mittelwert als 'after') erweitert und die Wahrscheinlichkeit des Szenarios mittels T-Test errechnet
$\\$

Nullhypothese: Die Arbeitszeit war vor dem Training kürzer/gleich.

$$H0: \mu_{before}\leq\mu_{after}$$  

Alternativhypothese: Das Training hat die Arbeitszeit verringert.

$$HA: \mu_{before}>\mu_{after}$$  

```{r Aufgabe1_Test_less}

# T-test Variante1 (mit 2 gepaarten Stichproben)
t.test(x = before,y=after,mu = 0,conf.level = 0.99,paired=TRUE,
alternative = c("greater"))

# T-test Variante1 (mit Differenzen)
t.test(diff,mu = 0,conf.level = 0.99,
alternative = c("greater"))

```

Die Teststatisik beträgt t = 4.9322. Der p-Wert liegt bei 0.0004055, somit kann die Nullhypothese sowohl auf dem 5% als auch auf dem 1% Niveau verworfen werden.

--> Das Training hat die mittlere Arbeitszeit verringert.
$\\$

ERWEITERUNG - BOOTSTRAPPING

Es werden 10.000 Bootstrap-Stichproben generiert (seed 1234) und die Häufigkeitsverteilung ihrer Mittelwerte sowie das zugehörige Konfidenzintervall für den tatsächlichen Mittelwert auf 95% und 99% Signifikanz bestimmt.

```{r Aufgabe1_Bootstrap_func}

library(boot)

bootstrap_diff_mean <- function(data, indices) 
  {
  sample <- data[indices] 
  return(mean(sample))
}

set.seed(1234)
num_resample <- 10000

bootstrap_res1 <- boot(diff_woOut, bootstrap_diff_mean, num_resample)
plot(bootstrap_res1)
(bootstrap_res1_95 <- boot.ci(bootstrap_res1, type = "perc", conf = 0.95))
(bootstrap_res1_99 <- boot.ci(bootstrap_res1, type = "perc", conf = 0.99))

```

Das Histogram der Bootstrap-Strichproben zeigt eine unimodale Verteilung mit einem zentralen Peak und guter Symmetrie und der Q-Q-plot zeigt kaum Abweichungen von der theoretischen Normalverteilung. Wie bei dem t-Test, zeigt auch Bootstrapping einen deutlichen Effekt des Training, sowohl für Konfidenzintervall 95% als auch 99%. Für das Konfidenzintervall von 99% liegt das Intervall der tatsächlichen Differenz (=Trainingseffekt) im Bereich [0.0700, 0.1178].   


## Aufgabe 2

Hatten auf der Titanic Frauen und Kinder eine signifkant (auf dem 1%
Niveau) bessere Überlebenschance als Männer?
(Tipp: Vergleichen Sie jeweils Frauen und Kinder separat.)

```{r Aufgabe2_Datenprüfung/-aufbereitung}

str(Titanic)

(men=apply(Titanic, c(2,4), sum)[1,])
(women=apply(Titanic, c(2,4), sum)[2,])
(children=apply(Titanic, c(3,4), sum)[1,])

```
Es sollen jeweils 2 Proportionen miteinander verglichen werden (Männer - Frauen / Männer - Kinder), daher wird der Proportionentest angewandt. 
Auf Basis des Grenzverteilungssatzes wird eine Normalverteilung der Daten angenommen.

1) Vergleich FRAUEN : MÄNNER

Nullhypothese: Frauen hatten keine besseren Überlebenschancen als Männer.

$$p(Frauen)\leq p(Männer)$$  

Alternativhypothese: Frauen hatten bessere Überlebenschancen als Männer.

$$p(Frauen) > p(Männer)$$  

```{r Aufgabe2_Test_women}

prop.test(c(women["Yes"],men["Yes"]),c(sum(women), sum(men)), alternative = "greater")

```
Die Teststatisik beträgt X-squared = 454.5. Aufgrund des p-Wertes mit < 2.2e-16, kann die Nullhypothese auf dem 1% Niveau verworfen werden.

--> Frauen hatten bessere Überlebenschancen als Männer.


2) Vergleich KINDER : MÄNNER

Nullhypothese: Kinder hatten keine besseren Überlebenschancen als Männer.

$$H0: p(Kinder)\leq p(Männer)$$  

Alternativhypothese: Kinder hatten bessere Überlebenschancen als Männer.

$$HA: p(Kinder) > p(Männer)$$  

```{r Aufgabe2_Test_children}

prop.test(c(children["Yes"],men["Yes"]),c(sum(children), sum(men)), alternative = "greater")

```
Die Teststatisik beträgt X-squared = 54.16. Aufgrund des p-Wertes mit < 9.24e-14, kann die Nullhypothese auf dem 1% Niveau verworfen werden.

--> Kinder hatten bessere Überlebenschancen als Männer.
$\\$

ERWEITERUNG - BAYES STATISTIK

Die Analyse wird mittels bayes.prop.test um eine simulationsbasierte Methode erweitert.

```{r Aufgabe2_Bayes_women}

library(BayesianFirstAid)

bayesFit_Titanic_woman <- BayesianFirstAid::bayes.prop.test(
  c(women["Yes"],men["Yes"]),c(sum(women), sum(men)), cred.mass = 0.99)
summary(bayesFit_Titanic_woman)
plot(bayesFit_Titanic_woman)
df_Titanic_woman <- as.data.frame(bayesFit_Titanic_woman)

```

Die Histogramme der A-posterior-Verteilungen zweigen unimodale, symmetrische Form mit geringer Streuung. Das Modell berrechnet eine mittlere Überlebenswahrscheinlichkeit für Frauen von 0.73, wobei das 99%-Konfidenzintervall  für die tatsächliche Wahrscheinlichkeit im Bereich [0.676,0.782] liegt. Für Männer wird eine Überlebenswahrscheinlichkeit von 0.212 errechnet, wobei das 99%-Konfidenzintervall im Bereich [0.188,0.236] liegt. Somit ergibt sich eine durchschnittliche Differenz der Überlebensraten von 0.519, mit einem 99%-Konfidenzintervall für die tatsächliche Differenz im Bereich [0.457, 0.574]. Frauen hatten somit deutlich höhere Überlebenschancen.


```{r Aufgabe2_Bayes_children}

bayesFit_Titanic_children <- BayesianFirstAid::bayes.prop.test(
  c(children["Yes"],men["Yes"]),c(sum(children), sum(men)), cred.mass = 0.99)
summary(bayesFit_Titanic_children)
plot(bayesFit_Titanic_children)
df_Titanic_children <- as.data.frame(bayesFit_Titanic_children)

```

Das Histogramm der A-posterior-Verteilung für Kinder zeigt eine unimodale, symmetrische Form, wobei die Streuung deutlich größer ist als bei den Frauen oder Männern aufgrund der kleineren Stichprobengröße. Daraus ergibt sich auch die breitere Streuung der Differenzen. Das Modell berrechnet eine mittlere Überlebenswahrscheinlichkeit für Kinder von 0.523, wobei das 99%-Konfidenzintervall für die tatsächliche Wahrscheinlichkeit im Bereich [0.405, 0.642] liegt. Somit ergibt sich eine durchschnittliche Differenz der Überlebensraten von 0.310, mit einem 99%-Konfidenzintervall für die tatsächliche Differenz im Bereich [0.187, 0.429]. Kinder hatten somit ebenfalls deutlich höhere Überlebenschancen. 


## Aufgabe 3

Ein Biologe vergleicht die mittleren Wachstumsraten einer Bakterienkultur
auf einer Petrischale über einen Zeitraum von 20 Miunten minütlich.
Es soll dabei untersucht werden, ob der Nährboden die Wachstumsrate
gegenüber der durchschnittlich zu erwartenden Wachstumsrate von 1%
fördert. 

```{r Aufgabe3_Datenprüfung/-aufbereitung}

growth_data <- c(0.146842, 0.156757, 0.091255, 0.063720, 0.148471, -0.045436, 0.150407,
0.077905, 0.077267, 0.026454, 0.090700, 0.245384, 0.129650, 0.141617, 0.039957,
0.165351, 0.029091, 0.073473, 0.189657, 0.123897)

qqnorm(growth_data)
qqline(growth_data,col=2)

shapiro.test(growth_data)

```

Weder der QQ-Plot noch der Shapiro-Test sprechen gegen die Nullhypothese, daher wird eine Normalverteilung der Daten angenommen.
Es soll die mittlere Wachstumsrate gegen den Referenzwert von 0.01 verglichen werden, daher wird ein 1-Sample t-test mit µ = 0.01 angewendet.


Nullhypothese: Das Nährmedium bietet keinen zusätzlichen Wachstumsvorteil.

$$H0: \mu_{normal}\geq\mu_{test}$$  

Alternativhypothese: Das Nährmedium bietet einen zusätzlichen Wachstumsvorteil.

$$HA: \mu_{normal}<\mu_{test}$$ 

```{r Aufgabe3_Test}

t.test(growth_data, mu = 0.01,
alternative = c("greater"))

```


Die Teststatisik beträgt t = 6.4434. Der p-Wert liegt bei 1.774e-06, somit kann die Nullhypothese verworfen werden.

--> Das Nährmedium bietet einen Wachstumsfaktor.


ERWEITERUNG - BAYES STATISTIK

```{r Aufgabe3_Bayes}

bayesFit_growth <- bayes.t.test(growth_data, mu = 0.01, cred.mass = 0.99)
summary(bayesFit_growth)
plot(bayesFit_growth)

```

Das bayesianische Modell liefert einen a-posterior-Mittelwert von 0.107 mit 99%-HDI im Bereich von [0.062, 0.149]. Somit bietet das Medium einen deutlichen Wachstumsvorteil. 

## Aufgabe 4

Eine Genontologieanalyse wird durchgeführt, um den Anteil von Genen
aus bestimmten Pfades (pathway) zu bestimmen, die an der Entwicklung
von Krebs beteiligt sind. Um die Frage zu beantworten, werden 720
mögliche Gene in Betracht gezogen, von denen 696 in einer
Studie gefunden wurden und daher glaubwürdig sind. Von diesen haben
413 mit der Krebsentwicklung zu tun. 

-) Testen Sie, ob der Anteil der beteiligten Genen sich signifikant gegenüber einer früheren Studie verändert hat, 
die 55% der Gene als beteiligt gefunden hat.Berechnen Sie das zugehörige 95% bzw. 99% Konidenzintervall für dieses Szenario.

Der Anteil an beteiligten Genen beträgt laut der aktuellen Studie rund 59% (=413/696). Es gilt über den 2-seitigen Proportionentest zu eruieren, ob die Abweichung zu einer früheren Studie (55%) als signifikant anzusehen ist. 

Nullhypothese: Die aktuelle Studie unterschiedet sich nicht von der früheren Studie.

$$H0: p(Gene) = 0.55 $$  

Alternativhypothese: Die aktuelle Studie unterschiedet sich von der früheren Studie.

$$HA: p(Gene) \ne 0.55 $$  

```{r Aufgabe4_Test}

prop.test(413, 696, p = 0.55, conf.level = 0.95)
prop.test(413, 696, p = 0.55, conf.level = 0.99)

```

Die Teststatistik beträgt X-squared = 5.1207, der p-Wert liegt bei 0.02364. Es handelt sich um einen 2-seitigen Test, daher kann die Nullhypothese auf dem 5% Niveau verworfen werden, muss auf dem 1% Niveau jedoch beibehalten werden. 
Dies wird auch anhand der zugehörigen Konfidenzintervalle sichtbar. Das 95%-ige Konfidenzintervall liegt zwischen [0.5557580, 0.6299782], inklusidert das Ergebnis der vorherigen Studie mit 55% somit nicht, während das 99%-ige Konfidenzintervall zwischen [0.5440439 0.6409477] liegt und das Ergebnis der früheren Studie mit 55% einschließt. 


ERWEITERUNG - BAYES STATISTIK

```{r Aufgabe4_Bayes}

bayesFit_pathway95 <- BayesianFirstAid::bayes.prop.test(416, 696, comp.theta = 0.55, cred.mass = 0.95)
bayesFit_pathway99 <- BayesianFirstAid::bayes.prop.test(416, 696, comp.theta = 0.55, cred.mass = 0.99)
summary(bayesFit_pathway95)
plot(bayesFit_pathway95)
summary(bayesFit_pathway99)
plot(bayesFit_pathway99)

```

Das bootstrapping Modell liefert einen theta-Wert von 0.597 bei einem 99%-HDI im Bereich [0.551, 0.645]. Die Anzahl der gefundenen Gene ist somit auf dem 1% Niveau signifikant höher als bei der vorhergehenden Studie, im Mittel um 0.048.


## Aufgabe 5

Bevor Sie einen job annehmen, möchten Sie als Kandidat oder Kandidatin
die Gehälter in den Firmen vergleichen, die beide bereit wären, Sie
anzustellen. Diverse Gehälter konnten Sie aufgrund von online Transparenzvorgaben
in Erfahrung bringen.Welche der Firmen bietet Ihnen das attraktivere Gehalt?

```{r Aufgabe5_Datenprüfung/-aufbereitung}

comp1 <- c(4218.874, 2323.970, 4104.761, 3172.519, 3058.287, 2386.729, 4405.709,
           2665.709, 5326.124, 2993.015,5152.121, 3164.876, 2703.269, 3837.005, 
           2927.137, 2847.995, 3087.938, 3063.339, 4697.341, 5602.379, 2992.996, 
           5052.060, 4095.423, 1668.059, 6268.097)

comp2 <- c(1888.252, 2429.395, 2062.037, 1932.138, 1788.335, 2119.263, 2185.819, 
           2173.098, 2391.626, 1576.546, 1871.540, 2405.640, 2470.771, 1879.237,
           2181.048, 2272.962, 2174.767, 1729.053, 1119.993, 2325.788, 2112.610, 
           2847.006, 1124.272, 5320.000, 4785.000)

comp2_woOut <- c(1888.252, 2429.395, 2062.037, 1932.138, 1788.335, 2119.263, 2185.819, 
           2173.098, 2391.626, 1576.546, 1871.540, 2405.640, 2470.771, 1879.237,
           2181.048, 2272.962, 2174.767, 1729.053, 1119.993, 2325.788, 2112.610, 
           2847.006, 1124.272)

par(mfrow=c(1,2))

qqnorm(comp1, main = "Normal Q-Q Plot - Firma_1")
qqline(comp1,col=2)

qqnorm(comp2, main = "Normal Q-Q Plot - Firma_2")
qqline(comp2,col=2)

shapiro.test(comp1)
shapiro.test(comp2)
shapiro.test(comp2_woOut)

summary(comp1)
summary(comp2)
summary(comp2_woOut)

boxplot(comp1, horizontal = T, main = "Firma_1", xlab = "Gehalt")
boxplot(comp2_woOut, horizontal = T, main = "Firma_2", xlab = "Gehalt")


hist(comp1, freq = F, main = "Firma_1", ylim = c(0,0.0004), xlab = "Gehalt")
lines(density(comp1))
hist(comp2_woOut, freq = F, main = "Firma_2", ylim = c(0,0.0006), xlab = "Gehalt")
lines(density(comp2_woOut))


```
Im Q-Q-Plot von Firma 2 sind zwei deutliche Ausreißer am rechten oberen Rand zu sehen, welche in weiterer Folge entfernt werden. Der Q-Q-Plot und das Histogramm zu den Daten von Firma 1 zeigen jeweils 2 Modi, somit kann der Shapiro-Test nicht angewandt werden und von Normalverteilung ist nicht auszugehen. 
Aufgrund dieser Datenverteilung ist kein statistischer Test anwendbar und es muss auf simulations-basierte Methoden zurückgegriffen werden.

ERWEITERUNG - BOOTSTRAPPING

Somit wird für die Analyse auf Bootstrapping zurückgegriffen.


```{r Aufgabe5_Boot}

salaries <- c(comp1, comp2_woOut)

boot_fn <- function(data, indices) {
  comp1_indices <- indices <= 25
  comp2_indices <- indices > 25
  
  # Data subsets based on indices
  group1_salaries <- data[comp1_indices]
  group2_salaries <- data[comp2_indices]
  
  #Calculate
  mean_group1 <- mean(group1_salaries)
  mean_group2 <- mean(group2_salaries)
  diff_means <- mean_group1 - mean_group2
  
  return(diff_means)
}

# Set seed for reproducibility
set.seed(123)

# Perform bootstrap resampling
boot_res5 <- boot(salaries, boot_fn, R = 10000)
plot(boot_res5)

# Calculate bootstrap confidence intervals
(boot_res5_ci95 <- boot.ci(boot_res5, type = "perc", conf = 0.95))
(boot_res5_ci95 <- boot.ci(boot_res5, type = "perc", conf = 0.99))

```

Das Histogram der Bootstrap-Strichproben zeigt eine unimodale Verteilung mit einem zentralen Peak nahe Null und guter Symmetrie und der Q-Q-plot zeigt kaum Abweichungen von der theoretischen Normalverteilung. Bootstrapping liefert ein 99%-Konfidenzintervall für die tatsächlich Differenz im Bereich von [-878, 878], somit kann kein signifikanter Unterschied zwischen den Gehältern der beiden Firmen festgestellt werden. 


